# 引言 {#sec-intro}

```{r}
#| label: setup-common-01
#| include: false
source("includes/common.R")
```

```{r}
#| label: setup-01
#| include: false
if (!identical(Sys.getenv("emlwr.eval_fits"), "true")) {
  eval_fits <- FALSE
} else {
  eval_fits <- TRUE
}
```

::: callout-note
虽然这一章是早期草稿，但它相对完整，对读者来说应该是连贯的。
:::

## 演示 {#sec-demonstration}

为了展示一些小小的直觉对评估机器学习模型时执行时间的巨大影响，我将通过一个快速的模型调优示例来说明。在第一次尝试中，我将依赖tidymodels的默认值和一个简单的网格搜索，在第二次尝试中，我将从我的袖子里拿出一些技巧，这些技巧将在几乎不降低预测性能的情况下大幅减少评估模型所需的时间。

### 设置 {#sec-setup}

首先，加载一些需要的包：

```{r}
#| label: load-pkgs
library(tidymodels)
library(future)
library(finetune)
library(bonsai)
```

为了这个示例，我们将模拟一个包含100,000行和18列的数据集。第一列`class`是一个二元结果，其余变量是数字和因子的混合。

```{r}
#| label: d-print
set.seed(1)
d <- simulate_classification(1e5)
d
```

有关这个数据集的更多信息，请参见@sec-datasets。

我们将首先将数据分割为训练集和测试集，然后从训练数据生成10个折叠用于交叉验证。

```{r}
#| label: d-split
set.seed(1)
d_split <- initial_split(d)
d_train <- training(d_split)
d_test <- testing(d_split)
d_folds <- vfold_cv(d_train)
```

### 第一次尝试 {#sec-first-go}

在我第一次尝试调优时，我将使用网格搜索来调整一个提升树模型。默认情况下，tidymodels将使用XGBoost作为建模引擎。我将尝试几个不同的`learn_rate`值——一个控制新添加的树对预测影响程度的参数——以及`trees`——集成中树的数量。

```{r}
#| label: bt
bt <- 
  boost_tree(learn_rate = tune(), trees = tune()) %>%
  set_mode("classification")
```

我将使用`tune_grid()`进行网格搜索，尝试`learn_rate`和`trees`的不同值对，并看看哪些有效。参数`grid = 12`表示我想尝试12种不同的值组合，并将让tidymodels确切地决定这些值是什么。

```{r}
#| label: bm-basic
#| eval: !expr eval_fits
set.seed(1)

bm_basic <- 
  bench::mark(
    basic = 
      tune_grid(
        object = bt,
        preprocessor = class ~ .,
        resamples = d_folds,
        grid = 12
      )
  )
```

```{r}
#| label: get-bm-basic
#| include: false
if (identical(eval_fits, "true")) {
  bm_basic <- trim_bench_mark(bm_basic)
  qsave(bm_basic, file = "data/intro/bm_basic.rds")
} else {
  bm_basic <- qread("data/intro/bm_basic.rds")
}
```

`bench::mark()`返回了这个过程所需的精确时间。

```{r}
#| label: bm-basic-print
bm_basic
```

天哪！`r round(as.numeric(bm_basic$median[[1]]) / 60 / 60, 2)`小时是相当长的一段时间。不过，`tune_grid()`到底做了什么呢？首先，我们来分解一下实际发生了多少次模型拟合。由于我提供了`grid = 12`，我们正在评估12种可能的模型配置。这些模型配置中的每一种都针对`d_folds`进行评估，这是一个`r nrow(d_folds)`折交叉验证对象，这意味着每种配置都拟合了`r nrow(d_folds)`次。那是`r nrow(d_folds) * 12`次模型拟合！此外，这些拟合发生在`r nrow(d_folds)-1`/`r nrow(d_folds)`的训练数据上，或者`r nrow(d_folds$splits[[1]])`行。

然而，通过一些小的改动，调整这个模型所需的时间可以被*大幅*减少。

### 快速尝试 {#sec-speedy-go}

为了减少评估这些模型所需的时间，我将进行4个小修改，这些修改只需要大约7行代码。

首先，我将**并行评估**：几乎所有现代笔记本电脑都有不止一个CPU核心，并且只需要1行代码就可以使用tidymodels在它们之间分配计算。

```{r}
plan(multisession, workers = 4)
```

虽然这个调优过程可以从更多的核心中受益，但我只在这里使用4个核心，以给出在典型笔记本电脑上可能的速度提升的真实画面。

::: callout-note
并行性是@sec-parallel-computing的主题。
:::

然后，我们将**使用一个巧妙的网格**；tidymodels框架实现了一种称为“子模型技巧”的技术，这将允许我们从比实际拟合的模型更多的模型中进行预测。而不是只提供`grid = 12`并让tidymodels自动生成网格，我将自己构建网格。

```{r}
set.seed(1)
bt_grid <- bt %>%
  extract_parameter_set_dials() %>% 
  grid_regular(levels = 4)
```

::: callout-note
要了解更多关于子模型技巧的信息，请参见@sec-submodel。
:::

接下来，我将**更换计算引擎**：用另一种能够更好地处理数据集某些属性的梯度提升模型替换XGBoost，将大大减少我们的拟合时间。

```{r}
bt_lgb <- bt %>% set_engine("lightgbm")
```

::: callout-note
@sec-models包含了tidymodels支持的许多建模引擎的基准测试和扩展属性的注释。
:::

最后，我将**提前放弃表现不佳的模型**：而不是使用`tune_grid()`进行网格搜索，我将使用一种称为*racing*的技术，当模型表现不佳时停止评估模型，使用`tune_race_anova()`函数。

```{r}
#| label: bm-speedy
#| eval: !expr eval_fits
set.seed(1)

bm_speedy <- 
  bench::mark(
    speedy = 
      tune_race_anova(
        object = bt_lgb,
        preprocessor = class ~ .,
        resamples = d_folds,
        grid = bt_grid
      )
  )
```

```{r}
#| label: get-bm-speedy
#| include: false
if (identical(eval_fits, "true")) {
  bm_speedy <- trim_bench_mark(bm_speedy)
  qsave(bm_speedy, file = "data/intro/bm_speedy.rds")
} else {
  bm_speedy <- qread("data/intro/bm_speedy.rds")
}
```

::: callout-note
替代搜索策略如racing在@sec-search中有详细说明。
:::

查看新的基准测试：

```{r}
#| label: bm-speedy-print
bm_speedy
```

```{r}
#| label: back-to-default
#| echo: false
plan("default")
```

调整总时间从`r round(as.numeric(bm_basic$median[[1]]) / 60 / 60, 2)`*小时*减少到`r round(as.numeric(bm_speedy$median[[1]]) / 60, 2)`*分钟*——第二种方法比第一种快了`r round(as.numeric(bm_basic[["median"]][[1]]) / as.numeric(bm_speedy[["median"]][[1]]))`倍。

看到这样的结果时，我首先会想，由于这种转变，我会在预测性能上受到多大的惩罚。让我们在测试集上评估这些调优结果中的顶级模型。首先，对于基本工作流程：

```{r}
#| label: fit-basic
#| eval: !expr eval_fits
fit_basic <- 
  select_best(bm_basic$result[[1]], metric = "roc_auc") %>%
  finalize_workflow(workflow(class ~ ., bt), parameters = .) %>%
  last_fit(split = d_split)
```

```{r}
#| label: get-fit-basic
#| include: false
if (identical(eval_fits, "true")) {
  qsave(fit_basic, file = "data/intro/fit_basic.rds")
} else {
  fit_basic <- qread("data/intro/fit_basic.rds")
}
```

```{r}
#| label: print-fit-basic-metrics
collect_metrics(fit_basic)
```

至于更快的方法：

```{r}
#| label: fit-speedy
#| eval: !expr eval_fits
fit_speedy <- 
  select_best(bm_speedy$result[[1]], metric = "roc_auc") %>%
  finalize_workflow(workflow(class ~ ., bt), parameters = .) %>%
  last_fit(split = d_split)
```

```{r}
#| label: get-fit-speedy
#| include: false
if (identical(eval_fits, "true")) {
  qsave(fit_speedy, file = "data/intro/fit_speedy.rds")
} else {
  fit_speedy <- qread("data/intro/fit_speedy.rds")
}
```

```{r}
#| label: print-fit-speedy-metrics
collect_metrics(fit_speedy)
```

性能结果几乎无法区分，在时间上仅用了`r round(100 * as.numeric(bm_speedy[["median"]][[1]]) / as.numeric(bm_basic[["median"]][[1]]), 1)`%。

## 我们的方法

这本书是为那些等待代码运行时间过长的tidymodels用户准备的。我通常假设用户已经熟悉使用tidyverse进行数据操作和可视化，以及使用tidymodels进行基础机器学习知识，比如使用性能指标对重新抽样的模型进行评估。对于前者，我推荐[@wickham2023]来提高速度——对于后者，[@kuhn2022]。如果你对这些书中的内容感到舒适，那你就准备好了。

现代笔记本电脑是了不起的。在过去几年制造的许多机器上使用tidymodels的用户，已经准备好基于数千万行数据交互式地开发机器学习模型。话虽如此，如果没有正确的信息，很容易错误地引入性能问题，导致即使是数万行数据的分析也变得难以处理。通常，tidymodels框架试图保护用户免犯这样的错误，并在我们控制范围内解决这些问题。同时，许多经典机器学习中的基础和常用方法都有理论上的改进，可以大幅减少经过时间，同时保持预测性能。tidymodels框架实现了许多这样的改进，这本书的目标是以全面和连贯的方式展示它们。读者在阅读这本书后，将获得一系列一行代码，这些代码可以减少开发机器学习模型所需的时间，数量级上减少。

## 难点

为了更好地理解如何减少使用tidymodels评估模型所需的时间，我们需要了解tidymodels的工作原理。

像许多其他机器学习的“统一框架”（mlr3、caret、scikit-learn（？））一样，tidymodels框架本身并不实现训练和预测模型的算法。相反，tidymodels提供了一个通用接口到建模*引擎*：提供`fit()`和`predict()`方法的包（或包中的函数）。

![一张代表使用tidymodels拟合机器学习模型所需时间的图表。中央部分，以绿色显示，代表建模引擎拟合或预测模型算法所需的时间。绿色部分，在建模引擎的两侧，代表tidymodels的“开销”。](figures/translate_diagram.png){#fig-fit-boost-tree fig-alt="一个由三部分组成的时间线图表，分别以绿色、橙色和绿色显示。第一部分标记为“将输入转换为引擎代码”，第二部分为“调用引擎代码”，第三部分为“转换引擎输出”。时间线上方是需要使用tidymodels拟合提升树的代码。" fig-align="center"}

当使用tidymodels进行拟合和预测时，“翻译”过程在@fig-fit-boost-tree中有所说明。一些代码运行所需的时间是由于将输入的统一代码“翻译”成引擎期望的特定语法，还有一些部分是由于将引擎返回的内容“翻译”成tidymodels返回的统一输出；这些部分都在tidymodels团队的控制范围内。其余的时间发生在建模引擎的代码内部。

在tidymodels团队控制范围内的时间部分以绿色显示，我将在这本书中称之为“开销”。与训练数据的大小相比，tidymodels的开销在时间上是相对恒定的。这个开销包括检查数据类型、处理错误和警告等任务——最重要的是——以编程方式组装对引擎函数的调用。

以橙色显示的时间部分代表实际的模型训练（或预测）。这部分由建模*引擎*实现，因此不在tidymodels团队的控制范围内。与开销相比，这段代码的经过时间非常受输入数据大小的影响；根据引擎的不同，训练或测试数据的行数或列数的增加可能会大幅增加给定模型的训练或预测时间。

::: callout-note
这些引擎实现的模型的算法复杂性在许多情况下都是众所周知的。同时，一些引擎实现的经过时间的行为往往与理论预测大相径庭。模型代码的回归可能会引入不当的减速，反之，性能优化可能导致经过时间比理论预测更好地扩展，这可能是某些引擎存在的原因。
:::

如@fig-fit-scale所示，开销负责的经过时间比例取决于引擎对给定数据集的拟合或预测速度。

![作为比例，tidymodels的开销是引擎拟合时间的函数。对于小数据集上的非常简单的拟合，tidymodels开销相当可观，但对于即使是中等复杂的模型拟合和/或中等大小的数据，开销的比例可以忽略不计。](figures/scaling_diagram.png){#fig-fit-scale fig-alt="与上图类似的图表，只是三个图表堆叠在一起。绿色部分的长度在每个图表中都是相同的，但橙色部分要么非常小，中等，要么很长。"}

由于tidymodels翻译的绝对开销相对恒定，当模型拟合或预测*非常*快时，开销才是经过时间的很大一部分。对于使用`lm()`拟合30个数据点的线性模型，这个开销是[持续基准测试](https://github.com/tidymodels/parsnip/blob/11a3ab942f131e9d612d4d37c4b77273be064aaf/tests/testthat/test_fit_interfaces.R#L171)保持在2/3以下。也就是说，在最坏的情况下，使用tidymodels拟合模型比使用引擎接口本身多花三倍时间。然而，对于许多引擎来说，这个开销对于即使是10,000行的拟合也是微不足道的百分比。因此，关注减少开销的经过时间是有价值的，因为框架不应该无意中引入导致开销随训练数据大小而扩展的回归，但总的来说，减少评估模型时的经过时间的难点在于减少建模引擎执行的计算时间。

接下来的问题则是*tidymodels如何减少它不拥有的建模引擎的经过时间？*为了回答这个问题，让我们重新审视@sec-first-go中的应用示例。在那个第一个示例中，代码对引擎的语法进行了一些翻译，设置了一些错误处理，然后拟合和预测了`r nrow(d_folds) * 12`个模型。

![使用tidymodels调优模型时的时间线图。现在，代表引擎代码的一个中央橙色部分变成了120个单独的部分，每个模型拟合一个。](figures/basic_resample.png){#fig-basic-resample fig-alt="与第一个图表类似，只是中间的橙色部分现在被分成了120个部分。当使用tidymodels重新抽样模型时，翻译步骤只需要发生一次，然后引擎代码针对每个数据子集和超参数组合被调用。"}

@fig-basic-resample描述了这个过程，我们按顺序评估所有`r nrow(d_folds) * 12`个模型。每个白色点在经过时间的引擎部分代表引擎的另一轮拟合和预测。记住，在现实中，对于即使是适度大小的数据集，代表tidymodels开销的绿色部分在比例上比表示的要小得多。

在@sec-speedy-go中，我做的第一件事是引入一个并行后端。在可用核心上分布引擎拟合本身就是一个游戏规则改变者，如@fig-parallel-resample所示。

![不是顺序拟合每个120个模型，并行性允许我们同时拟合与我们拥有的CPU核心一样多的模型。](figures/parallel_resample.png){#fig-parallel-resample fig-alt="与上述图表相同，只是橙色部分的时间线现在被分成了4个部分并堆叠在一起。图表的宽度是之前的1/4。"}

然后，更换计算引擎为更高性能的替代品进一步减少了经过时间，如@fig-parallel-resample-opt所示。

![根据建模上下文的不同，某些建模引擎比其他引擎评估得更快。](figures/parallel_resample_opt.png){#fig-parallel-resample-opt fig-alt="与上述图表相同，尽管现在每个橙色部分的宽度是之前的一半。图表的宽度现在是之前的一半。"}

最后，如@fig-parallel-resample-opt2所示，@sec-submodel中描述的子模型技巧和@sec-search中描述的racing消除了大量的引擎拟合。

![通过racing和子模型技巧，我们可以评估与之前相同数量的潜在模型，同时拟合更少的模型。](figures/parallel_resample_opt2.png){#fig-parallel-resample-opt2 fig-alt="与之前相同的图表，只是大约2/3的橙色部分已被移除。"}

tidymodels团队投入大量精力确保支持最性能的并行化技术、建模引擎、模型特定优化和搜索技术。这本书将展示如何最好地利用这些特性来减少评估机器学习模型所需的时间。

## 数据集 {#sec-datasets}

在@sec-setup中，我使用了一个函数`simulate_classification()`来生成数据。这是两个函数之一，另一个是`simulate_regression()`，它们创建了这本书中许多实验的基础数据。

这两个函数是modeldata包中类似命名的`sim_classification()`和`sim_regression()`函数的改编版。它们对那些函数进行了小幅改动——即引入了一些具有棘手分布的因子预测器——这使得一些建模引擎出现了减速。

给定行数，`sim_classification()`生成一个有相应行数和16列的tibble：

```{r}
#| label: print-simulate-classification
d_class <- simulate_classification(1000)

d_class
```

最左边的列`class`是二元结果变量，其余列是预测变量。这些预测变量对我们将在本书中基准测试的建模函数提出了一些挑战。

首先，预测变量之间的相关性适中。相关性高的预测变量可能导致参数估计不稳定，使模型对数据的微小变化更加敏感。此外，相关性高的预测变量可能导致梯度下降过程（如驱动XGBoost和LightGBM等梯度提升树）的收敛速度变慢，因为损失函数的表面变得狭长，导致算法在逼近最优值时出现之字形，从而显著增加了训练时间。

```{r}
#| label: correlate-d-class
#| echo: false
library(corrr)

correlate(d_class) %>% 
  autoplot(low = "#c46938", high = "#3d6c56")
```

其次，有一些因子预测变量。由于多种原因，许多建模引擎在处理许多因子预测变量时训练时间会变长。首先，大多数建模引擎最终在数值矩阵上实现训练程序，要求因子预测变量以某种方式被编码为数字。在R中，这通常以处理对比的形式出现，其中长度为$n$的因子如果有$l$个水平，就被表示为一个由零和一组成的$n ~x~ l-1$矩阵。每一列被称为一个虚拟变量。当因子的第$i$个条目是第二水平时，第一列的值为$1$，否则为零。当因子的第$i$个条目是第三水平时，第二列的值为$1$，否则为零。如果结果矩阵的第$i$列的所有条目都为零，则我们知道第一个因子的第$i$个条目取的是第一水平。虽然这种因子表示方法相对简单，但它非常耗费内存；一个有100个水平的因子最终将需要一个99列的矩阵被分配以便被包含在模型中。虽然许多R中的建模引擎假设因子将被编码为处理对比，但不同的建模引擎对处理因子变量有不同的方法，其中一些比其他的更有效。更多内容见@sec-sparsity。

```{r}
#| label: represent-factors-as-dummy
#| echo: false
df <- data.frame(x = factor(letters[1:3]))
mm <- as.data.frame(model.matrix(~x, df))[-1]
```

:::::: columns
::: {.column width="45%"}
原始因子

```{r, echo = FALSE}
df
```
:::

::: {.column width="10%"}
<!-- 空列以创建间隙 -->
:::

::: {.column width="45%"}
处理对比的因子

```{r, echo = FALSE}
mm
```
:::
::::::

此外，许多这些因子变量存在类别不平衡；也就是说，因子的一些水平出现的频率远高于其他水平。一些模型可能难以从出现频率较低的类别中学习，可能需要更多的下降过程迭代才能使一些模型收敛。即使情况并非如此，在内存使用方面，为在许多行的数据集中只出现几次的因子水平分配一个虚拟变量也可能是“值得的”。

```{r}
#| label: factors-d-class
#| echo: false
#| fig-cap: "模拟数据中分类变量的分布。虽然结果`class`中的因子水平平衡得很好，但预测器中的一些因子水平比其他水平更常见，这可能导致许多建模算法不稳定。"
#| fig-alt: "5个条形图，一个接一个地堆叠在一起。每一行代表数据d中的一个因子列，每一列给出每个列水平的观测计数。结果`class`相对平衡，而每个预测器都有显著的类别不平衡。"
d_class %>%
  select(where(is.factor)) %>%
  summarize(across(everything(), ~list(table(.x)))) %>%
  pivot_longer(cols = everything(), names_to = "variable") %>%
  rowwise() %>%
  mutate(
    level_1 = rlang::try_fetch(value[[1]], error = function(cnd) {NA}),
    level_2 = rlang::try_fetch(value[[2]], error = function(cnd) {NA}),
    level_3 = rlang::try_fetch(value[[3]], error = function(cnd) {NA}),
    level_4 = rlang::try_fetch(value[[4]], error = function(cnd) {NA}),
    level_5 = rlang::try_fetch(value[[5]], error = function(cnd) {NA})
  ) %>%
  select(-value) %>%
  pivot_longer(cols = starts_with("level_"), names_to = "level", values_to = "n") %>%
  ggplot() +
  aes(x = level, y = n) +
  geom_col() +
  facet_grid(rows = vars(variable)) +
  theme_minimal() +
  labs(x = "因子水平", y = "观测次数")
```

<!--# TODO: 是否有可能在不适用的行/列中移除面板网格？ -->

回归数据集看起来非常相似。

```{r}
#| label: print-simulate-regression
d_reg <- simulate_regression(1000)

d_reg
```

最左边的列`outcome`是数值结果，其余15列是数值和因子的混合。与相关性和棘手的因子不平衡相关的故事也适用于回归数据集。证明这一点是家庭作业。

<!--# todo: 这不是“真实”的数据 -->

